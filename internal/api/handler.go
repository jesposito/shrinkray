package api

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"strings"
	"sync"
	"time"

	shrinkray "github.com/gwlsn/shrinkray"
	"github.com/gwlsn/shrinkray/internal/browse"
	"github.com/gwlsn/shrinkray/internal/config"
	"github.com/gwlsn/shrinkray/internal/ffmpeg"
	"github.com/gwlsn/shrinkray/internal/jobs"
	"github.com/gwlsn/shrinkray/internal/ntfy"
	"github.com/gwlsn/shrinkray/internal/pushover"
)

// Handler provides HTTP API handlers
type Handler struct {
	browser    *browse.Browser
	queue      *jobs.Queue
	workerPool *jobs.WorkerPool
	cfg        *config.Config
	cfgPath    string
	pushover   *pushover.Client
	ntfy       *ntfy.Client
	notifyMu   sync.Mutex // Protects notification sending to prevent duplicates
}

// NewHandler creates a new API handler
func NewHandler(browser *browse.Browser, queue *jobs.Queue, workerPool *jobs.WorkerPool, cfg *config.Config, cfgPath string) *Handler {
	browser.SetHideProcessingTmp(cfg.HideProcessingTmp)
	return &Handler{
		browser:    browser,
		queue:      queue,
		workerPool: workerPool,
		cfg:        cfg,
		cfgPath:    cfgPath,
		pushover:   pushover.NewClient(cfg.PushoverUserKey, cfg.PushoverAppToken),
		ntfy:       ntfy.NewClient(cfg.NtfyServer, cfg.NtfyTopic, cfg.NtfyToken),
	}
}

// response helpers

func writeJSON(w http.ResponseWriter, status int, data interface{}) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(status)
	json.NewEncoder(w).Encode(data)
}

func writeError(w http.ResponseWriter, status int, message string) {
	writeJSON(w, status, map[string]string{"error": message})
}

// Browse handles GET /api/browse?path=...
func (h *Handler) Browse(w http.ResponseWriter, r *http.Request) {
	path := r.URL.Query().Get("path")
	if path == "" {
		path = h.cfg.MediaPath
	}

	ctx, cancel := context.WithTimeout(r.Context(), 30*time.Second)
	defer cancel()

	result, err := h.browser.Browse(ctx, path)
	if err != nil {
		writeError(w, http.StatusInternalServerError, err.Error())
		return
	}

	processedPaths := h.queue.ProcessedPaths()
	if len(processedPaths) > 0 {
		for _, entry := range result.Entries {
			if entry.IsDir {
				entry.ProcessedCount = countProcessedInDir(entry.Path, processedPaths, h.cfg.HideProcessingTmp)
				continue
			}
			if _, ok := processedPaths[entry.Path]; ok {
				entry.Processed = true
			}
		}
	}

	pendingPaths := h.queue.PendingPaths()
	if len(pendingPaths) > 0 {
		for _, entry := range result.Entries {
			if entry.IsDir {
				entry.Pending = hasPendingInDir(entry.Path, pendingPaths, h.cfg.HideProcessingTmp)
				continue
			}
			if _, ok := pendingPaths[entry.Path]; ok {
				entry.Pending = true
			}
		}
	}

	writeJSON(w, http.StatusOK, result)
}

func countProcessedInDir(dirPath string, processedPaths map[string]struct{}, hideProcessingTmp bool) int {
	if len(processedPaths) == 0 {
		return 0
	}
	prefix := dirPath + string(os.PathSeparator)
	count := 0
	for path := range processedPaths {
		if strings.HasPrefix(path, prefix) {
			if hideProcessingTmp {
				lowerPath := strings.ToLower(path)
				if strings.HasSuffix(lowerPath, "shrinkray.tmp") || strings.Contains(lowerPath, ".shrinkray.tmp.") {
					continue
				}
			}
			count++
		}
	}
	return count
}

func hasPendingInDir(dirPath string, pendingPaths map[string]struct{}, hideProcessingTmp bool) bool {
	if len(pendingPaths) == 0 {
		return false
	}
	prefix := dirPath + string(os.PathSeparator)
	for path := range pendingPaths {
		if strings.HasPrefix(path, prefix) {
			if hideProcessingTmp {
				lowerPath := strings.ToLower(path)
				if strings.HasSuffix(lowerPath, "shrinkray.tmp") || strings.Contains(lowerPath, ".shrinkray.tmp.") {
					continue
				}
			}
			return true
		}
	}
	return false
}

// Presets handles GET /api/presets
func (h *Handler) Presets(w http.ResponseWriter, r *http.Request) {
	presets := ffmpeg.ListPresets()
	writeJSON(w, http.StatusOK, presets)
}

// Encoders handles GET /api/encoders
func (h *Handler) Encoders(w http.ResponseWriter, r *http.Request) {
	encoders := ffmpeg.ListAvailableEncoders()
	best := ffmpeg.GetBestEncoder()

	writeJSON(w, http.StatusOK, map[string]interface{}{
		"encoders": encoders,
		"best":     best,
	})
}

// CreateJobsRequest is the request body for creating jobs
type CreateJobsRequest struct {
	Paths             []string `json:"paths"`
	PresetID          string   `json:"preset_id"`
	IncludeSubfolders *bool    `json:"include_subfolders,omitempty"` // Default: true (for backwards compatibility)
	MaxDepth          *int     `json:"max_depth,omitempty"`          // nil = unlimited, 0 = current dir only, 1 = one level, etc.
	ExcludeProcessed  *bool    `json:"exclude_processed,omitempty"`
}

// MarkProcessedRequest is the request body for marking processed paths.
type MarkProcessedRequest struct {
	Paths             []string `json:"paths"`
	IncludeSubfolders *bool    `json:"include_subfolders,omitempty"`
}

// CreateJobs handles POST /api/jobs
// Responds immediately and processes files in background to avoid UI freeze
func (h *Handler) CreateJobs(w http.ResponseWriter, r *http.Request) {
	var req CreateJobsRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		writeError(w, http.StatusBadRequest, "invalid request body")
		return
	}

	if len(req.Paths) == 0 {
		writeError(w, http.StatusBadRequest, "no paths provided")
		return
	}

	preset := ffmpeg.GetPreset(req.PresetID)
	if preset == nil {
		writeError(w, http.StatusBadRequest, fmt.Sprintf("unknown preset: %s", req.PresetID))
		return
	}

	// Respond immediately - jobs will be added in background and appear via SSE
	writeJSON(w, http.StatusAccepted, map[string]interface{}{
		"status":  "processing",
		"message": fmt.Sprintf("Processing %d paths in background...", len(req.Paths)),
	})

	log.Printf("[api] CreateJobs: received %d paths, preset=%s", len(req.Paths), req.PresetID)
	for i, p := range req.Paths {
		log.Printf("[api] CreateJobs: path[%d] = %s", i, p)
	}

	// Process in background goroutine
	go func() {
		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
		defer cancel()

		// Build options for video file discovery
		// Default to recursive for backwards compatibility
		opts := browse.GetVideoFilesOptions{
			Recursive: true,
			MaxDepth:  req.MaxDepth,
		}
		if req.IncludeSubfolders != nil {
			opts.Recursive = *req.IncludeSubfolders
		}

		log.Printf("[api] CreateJobs background: deferred_probing=%v, recursive=%v, paths=%v",
			h.cfg.Features.DeferredProbing, opts.Recursive, req.Paths)

		excludeProcessed := req.ExcludeProcessed != nil && *req.ExcludeProcessed
		var processedPaths map[string]struct{}
		if excludeProcessed {
			processedPaths = h.queue.ProcessedPaths()
		}
		queuedPaths := h.queue.EnqueuedPaths()

		// Check if deferred probing is enabled
		if h.cfg.Features.DeferredProbing {
			// Streaming discovery: add jobs immediately without probing
			// Files are probed by workers when they pick up the job
			files, err := h.browser.DiscoverVideoFiles(ctx, req.Paths, opts)
			if err != nil {
				log.Printf("[api] Error discovering video files: %v", err)
				return
			}

			if excludeProcessed && len(processedPaths) > 0 {
				filtered := make([]browse.DiscoveredFile, 0, len(files))
				for _, file := range files {
					if _, ok := processedPaths[file.Path]; ok {
						continue
					}
					filtered = append(filtered, file)
				}
				files = filtered
			}
			if len(queuedPaths) > 0 {
				filtered := make([]browse.DiscoveredFile, 0, len(files))
				for _, file := range files {
					if _, ok := queuedPaths[file.Path]; ok {
						continue
					}
					filtered = append(filtered, file)
				}
				files = filtered
			}

			if len(files) == 0 {
				log.Printf("[api] No video files found in paths: %v (recursive=%v)", req.Paths, opts.Recursive)
				return
			}

			log.Printf("[api] Discovered %d video files, adding as pending_probe", len(files))

			// Convert to FileInfo for queue
			fileInfos := make([]jobs.FileInfo, len(files))
			for i, f := range files {
				fileInfos[i] = jobs.FileInfo{
					Path: f.Path,
					Size: f.Size,
				}
			}

			// Add jobs in pending_probe status - SSE will notify frontend
			h.queue.AddMultipleWithoutProbe(fileInfos, req.PresetID)
		} else {
			// Original behavior: probe all files first (slower but complete info)
			probes, err := h.browser.GetVideoFilesWithOptions(ctx, req.Paths, opts)
			if err != nil {
				fmt.Printf("Error getting video files: %v\n", err)
				return
			}

			if excludeProcessed && len(processedPaths) > 0 {
				filtered := make([]*ffmpeg.ProbeResult, 0, len(probes))
				for _, probe := range probes {
					if _, ok := processedPaths[probe.Path]; ok {
						continue
					}
					filtered = append(filtered, probe)
				}
				probes = filtered
			}
			if len(queuedPaths) > 0 {
				filtered := make([]*ffmpeg.ProbeResult, 0, len(probes))
				for _, probe := range probes {
					if _, ok := queuedPaths[probe.Path]; ok {
						continue
					}
					filtered = append(filtered, probe)
				}
				probes = filtered
			}

			if len(probes) == 0 {
				return
			}

			// Add jobs to queue - SSE will notify frontend of new jobs
			h.queue.AddMultiple(probes, req.PresetID)
		}
	}()
}

// MarkProcessed handles POST /api/processed/mark
func (h *Handler) MarkProcessed(w http.ResponseWriter, r *http.Request) {
	var req MarkProcessedRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		writeError(w, http.StatusBadRequest, "invalid request body")
		return
	}

	if len(req.Paths) == 0 {
		writeError(w, http.StatusBadRequest, "no paths provided")
		return
	}

	opts := browse.GetVideoFilesOptions{
		Recursive: true,
		MaxDepth:  nil,
	}
	if req.IncludeSubfolders != nil {
		opts.Recursive = *req.IncludeSubfolders
	}

	ctx, cancel := context.WithTimeout(r.Context(), 2*time.Minute)
	defer cancel()

	files, err := h.browser.DiscoverVideoFiles(ctx, req.Paths, opts)
	if err != nil {
		writeError(w, http.StatusInternalServerError, err.Error())
		return
	}

	if len(files) == 0 {
		writeError(w, http.StatusBadRequest, "no video files found")
		return
	}

	paths := make([]string, 0, len(files))
	for _, file := range files {
		paths = append(paths, file.Path)
	}

	added := h.queue.MarkProcessedPaths(paths)
	writeJSON(w, http.StatusOK, map[string]interface{}{
		"processed": added,
		"total":     len(paths),
	})
}

// ListJobs handles GET /api/jobs
func (h *Handler) ListJobs(w http.ResponseWriter, r *http.Request) {
	allJobs := h.queue.GetAll()
	stats := h.queue.Stats()

	writeJSON(w, http.StatusOK, map[string]interface{}{
		"jobs":  allJobs,
		"stats": stats,
	})
}

// GetJob handles GET /api/jobs/:id
func (h *Handler) GetJob(w http.ResponseWriter, r *http.Request) {
	// Extract ID from path - expects /api/jobs/{id}
	id := r.PathValue("id")
	if id == "" {
		writeError(w, http.StatusBadRequest, "job ID required")
		return
	}

	job := h.queue.Get(id)
	if job == nil {
		writeError(w, http.StatusNotFound, "job not found")
		return
	}

	writeJSON(w, http.StatusOK, job)
}

// CancelJob handles DELETE /api/jobs/:id
func (h *Handler) CancelJob(w http.ResponseWriter, r *http.Request) {
	id := r.PathValue("id")
	if id == "" {
		writeError(w, http.StatusBadRequest, "job ID required")
		return
	}

	job := h.queue.Get(id)
	if job == nil {
		writeError(w, http.StatusNotFound, "job not found")
		return
	}

	if job.Status == jobs.StatusFailed || job.Status == jobs.StatusCancelled {
		if _, err := h.queue.Remove(id); err != nil {
			writeError(w, http.StatusInternalServerError, err.Error())
			return
		}
		writeJSON(w, http.StatusOK, map[string]string{"status": "removed"})
		return
	}

	if job.Status == jobs.StatusComplete {
		writeError(w, http.StatusConflict, "completed jobs cannot be removed")
		return
	}

	// If job is running, cancel it via worker pool
	if job.Status == jobs.StatusRunning {
		h.workerPool.CancelJob(id)
	}

	// Cancel in queue
	if err := h.queue.CancelJob(id); err != nil {
		// Might already be cancelled/completed
		writeError(w, http.StatusConflict, err.Error())
		return
	}

	writeJSON(w, http.StatusOK, map[string]string{"status": "cancelled"})
}

// PauseJob handles POST /api/jobs/:id/pause
func (h *Handler) PauseJob(w http.ResponseWriter, r *http.Request) {
	id := r.PathValue("id")
	if id == "" {
		writeError(w, http.StatusBadRequest, "job ID required")
		return
	}

	job := h.queue.Get(id)
	if job == nil {
		writeError(w, http.StatusNotFound, "job not found")
		return
	}

	if job.Status != jobs.StatusRunning {
		writeError(w, http.StatusConflict, "job is not running")
		return
	}

	if h.workerPool.PauseJob(id) {
		writeJSON(w, http.StatusOK, map[string]string{"status": "paused"})
	} else {
		writeError(w, http.StatusConflict, "failed to pause job")
	}
}

// ResumeJob handles POST /api/jobs/:id/resume
func (h *Handler) ResumeJob(w http.ResponseWriter, r *http.Request) {
	id := r.PathValue("id")
	if id == "" {
		writeError(w, http.StatusBadRequest, "job ID required")
		return
	}

	job := h.queue.Get(id)
	if job == nil {
		writeError(w, http.StatusNotFound, "job not found")
		return
	}

	if job.Status != jobs.StatusRunning {
		writeError(w, http.StatusConflict, "job is not running")
		return
	}

	if h.workerPool.ResumeJob(id) {
		writeJSON(w, http.StatusOK, map[string]string{"status": "resumed"})
	} else {
		writeError(w, http.StatusConflict, "failed to resume job")
	}
}

// ReorderJob handles POST /api/jobs/:id/reorder
func (h *Handler) ReorderJob(w http.ResponseWriter, r *http.Request) {
	type reorderJobRequest struct {
		Direction string `json:"direction"`
	}

	id := r.PathValue("id")
	if id == "" {
		writeError(w, http.StatusBadRequest, "job ID required")
		return
	}

	job := h.queue.Get(id)
	if job == nil {
		writeError(w, http.StatusNotFound, "job not found")
		return
	}

	if job.Status != jobs.StatusPending && job.Status != jobs.StatusPendingProbe {
		writeError(w, http.StatusConflict, "job is not pending")
		return
	}

	var req reorderJobRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil && err != io.EOF {
		writeError(w, http.StatusBadRequest, "invalid request body")
		return
	}
	if req.Direction == "" {
		writeError(w, http.StatusBadRequest, "direction required")
		return
	}

	moved, err := h.queue.ReorderPending(id, req.Direction)
	if err != nil {
		writeError(w, http.StatusBadRequest, err.Error())
		return
	}

	writeJSON(w, http.StatusOK, map[string]interface{}{
		"moved": moved,
	})
}

// MoveJob handles POST /api/jobs/:id/move
func (h *Handler) MoveJob(w http.ResponseWriter, r *http.Request) {
	type moveJobRequest struct {
		BeforeID string `json:"before_id"`
	}

	id := r.PathValue("id")
	if id == "" {
		writeError(w, http.StatusBadRequest, "job ID required")
		return
	}

	job := h.queue.Get(id)
	if job == nil {
		writeError(w, http.StatusNotFound, "job not found")
		return
	}

	if job.Status != jobs.StatusPending && job.Status != jobs.StatusPendingProbe {
		writeError(w, http.StatusConflict, "job is not pending")
		return
	}

	var req moveJobRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil && err != io.EOF {
		writeError(w, http.StatusBadRequest, "invalid request body")
		return
	}

	moved, err := h.queue.MovePending(id, req.BeforeID)
	if err != nil {
		writeError(w, http.StatusBadRequest, err.Error())
		return
	}

	writeJSON(w, http.StatusOK, map[string]interface{}{
		"moved": moved,
	})
}

// ClearQueue handles POST /api/jobs/clear
func (h *Handler) ClearQueue(w http.ResponseWriter, r *http.Request) {
	type clearQueueRequest struct {
		IncludeCompleted *bool `json:"include_completed"`
	}

	includeCompleted := true
	var req clearQueueRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil && err != io.EOF {
		writeError(w, http.StatusBadRequest, "invalid request body")
		return
	}
	if req.IncludeCompleted != nil {
		includeCompleted = *req.IncludeCompleted
	}

	count := h.queue.Clear(includeCompleted)
	writeJSON(w, http.StatusOK, map[string]interface{}{
		"cleared": count,
		"message": fmt.Sprintf("Cleared %d jobs", count),
	})
}

// ClearProcessedHistory handles POST /api/processed/clear
func (h *Handler) ClearProcessedHistory(w http.ResponseWriter, r *http.Request) {
	count := h.queue.ClearProcessedHistory()
	writeJSON(w, http.StatusOK, map[string]interface{}{
		"cleared": count,
		"message": fmt.Sprintf("Cleared %d processed items", count),
	})
}

// GetConfig handles GET /api/config
func (h *Handler) GetConfig(w http.ResponseWriter, r *http.Request) {
	// Return a sanitized config (no sensitive paths exposed)
	writeJSON(w, http.StatusOK, map[string]interface{}{
		"version":                 shrinkray.Version,
		"media_path":              h.cfg.MediaPath,
		"original_handling":       h.cfg.OriginalHandling,
		"subtitle_handling":       h.cfg.SubtitleHandling,
		"workers":                 h.cfg.Workers,
		"has_temp_path":           h.cfg.TempPath != "",
		"pushover_user_key":       h.cfg.PushoverUserKey,
		"pushover_app_token":      h.cfg.PushoverAppToken,
		"pushover_configured":     h.pushover.IsConfigured(),
		"ntfy_server":             h.cfg.NtfyServer,
		"ntfy_topic":              h.cfg.NtfyTopic,
		"ntfy_token":              h.cfg.NtfyToken,
		"ntfy_configured":         h.ntfy.IsConfigured(),
		"notify_on_complete":      h.cfg.NotifyOnComplete,
		"hide_processing_tmp":     h.cfg.HideProcessingTmp,
		"allow_software_fallback": h.cfg.AllowSoftwareFallback,
		"layout":                  h.cfg.Layout,
		"auth_enabled":            h.cfg.Auth.Enabled,
		"auth_provider":           h.cfg.Auth.Provider,
		// Feature flags for frontend
		"features": map[string]bool{
			"virtual_scroll":   h.cfg.Features.VirtualScroll,
			"deferred_probing": h.cfg.Features.DeferredProbing,
			"paginated_init":   h.cfg.Features.PaginatedInit,
			"batched_sse":      h.cfg.Features.BatchedSSE,
			"delta_progress":   h.cfg.Features.DeltaProgress,
		},
	})
}

// UpdateConfigRequest is the request body for updating config
type UpdateConfigRequest struct {
	OriginalHandling      *string `json:"original_handling,omitempty"`
	SubtitleHandling      *string `json:"subtitle_handling,omitempty"`
	Workers               *int    `json:"workers,omitempty"`
	PushoverUserKey       *string `json:"pushover_user_key,omitempty"`
	PushoverAppToken      *string `json:"pushover_app_token,omitempty"`
	NtfyServer            *string `json:"ntfy_server,omitempty"`
	NtfyTopic             *string `json:"ntfy_topic,omitempty"`
	NtfyToken             *string `json:"ntfy_token,omitempty"`
	NotifyOnComplete      *bool   `json:"notify_on_complete,omitempty"`
	HideProcessingTmp     *bool   `json:"hide_processing_tmp,omitempty"`
	AllowSoftwareFallback *bool   `json:"allow_software_fallback,omitempty"`
	Layout                *string `json:"layout,omitempty"`
}

// UpdateConfig handles PUT /api/config
func (h *Handler) UpdateConfig(w http.ResponseWriter, r *http.Request) {
	var req UpdateConfigRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		writeError(w, http.StatusBadRequest, "invalid request body")
		return
	}

	// Only allow updating certain fields
	if req.OriginalHandling != nil {
		if *req.OriginalHandling != "replace" && *req.OriginalHandling != "keep" {
			writeError(w, http.StatusBadRequest, "original_handling must be 'replace' or 'keep'")
			return
		}
		h.cfg.OriginalHandling = *req.OriginalHandling
	}
	if req.SubtitleHandling != nil {
		if *req.SubtitleHandling != "convert" && *req.SubtitleHandling != "drop" {
			writeError(w, http.StatusBadRequest, "subtitle_handling must be 'convert' or 'drop'")
			return
		}
		h.cfg.SubtitleHandling = *req.SubtitleHandling
	}

	if req.Workers != nil && *req.Workers > 0 {
		workers := *req.Workers
		if workers > 6 {
			workers = 6 // Cap at 6 workers
		}
		// Dynamically resize the worker pool
		h.workerPool.Resize(workers)
	}

	// Handle Pushover settings
	if req.PushoverUserKey != nil {
		h.cfg.PushoverUserKey = *req.PushoverUserKey
		h.pushover.UserKey = *req.PushoverUserKey
	}
	if req.PushoverAppToken != nil {
		h.cfg.PushoverAppToken = *req.PushoverAppToken
		h.pushover.AppToken = *req.PushoverAppToken
	}
	if req.NtfyServer != nil {
		h.cfg.NtfyServer = *req.NtfyServer
		h.ntfy.ServerURL = *req.NtfyServer
	}
	if req.NtfyTopic != nil {
		h.cfg.NtfyTopic = *req.NtfyTopic
		h.ntfy.Topic = *req.NtfyTopic
	}
	if req.NtfyToken != nil {
		h.cfg.NtfyToken = *req.NtfyToken
		h.ntfy.Token = *req.NtfyToken
	}
	if req.NotifyOnComplete != nil {
		h.cfg.NotifyOnComplete = *req.NotifyOnComplete
	}
	if req.HideProcessingTmp != nil {
		h.cfg.HideProcessingTmp = *req.HideProcessingTmp
		h.browser.SetHideProcessingTmp(*req.HideProcessingTmp)
	}
	if req.AllowSoftwareFallback != nil {
		h.cfg.AllowSoftwareFallback = *req.AllowSoftwareFallback
	}
	if req.Layout != nil {
		if *req.Layout != "classic" && *req.Layout != "tabs" {
			writeError(w, http.StatusBadRequest, "layout must be 'classic' or 'tabs'")
			return
		}
		h.cfg.Layout = *req.Layout
	}

	// Persist config to disk
	if h.cfgPath != "" {
		if err := h.cfg.Save(h.cfgPath); err != nil {
			writeError(w, http.StatusInternalServerError, fmt.Sprintf("failed to save config: %v", err))
			return
		}
	}

	writeJSON(w, http.StatusOK, map[string]string{"status": "updated"})
}

// Stats handles GET /api/stats
func (h *Handler) Stats(w http.ResponseWriter, r *http.Request) {
	stats := h.queue.Stats()
	writeJSON(w, http.StatusOK, stats)
}

// ClearCache handles POST /api/cache/clear
func (h *Handler) ClearCache(w http.ResponseWriter, r *http.Request) {
	h.browser.ClearCache()
	writeJSON(w, http.StatusOK, map[string]string{"status": "cache cleared"})
}

// TestPushover handles POST /api/pushover/test
func (h *Handler) TestPushover(w http.ResponseWriter, r *http.Request) {
	if !h.pushover.IsConfigured() {
		writeError(w, http.StatusBadRequest, "Pushover credentials not configured")
		return
	}

	if err := h.pushover.Test(); err != nil {
		writeError(w, http.StatusBadRequest, err.Error())
		return
	}

	writeJSON(w, http.StatusOK, map[string]string{"status": "Test notification sent"})
}

// TestNtfy handles POST /api/ntfy/test
func (h *Handler) TestNtfy(w http.ResponseWriter, r *http.Request) {
	if !h.ntfy.IsConfigured() {
		writeError(w, http.StatusBadRequest, "ntfy credentials not configured")
		return
	}

	if err := h.ntfy.Test(); err != nil {
		writeError(w, http.StatusBadRequest, err.Error())
		return
	}

	writeJSON(w, http.StatusOK, map[string]string{"status": "Test notification sent"})
}

// GetPushover returns the Pushover client (for SSE handler)
func (h *Handler) GetPushover() *pushover.Client {
	return h.pushover
}

// ApplyConfig updates runtime configuration from a freshly loaded config.
func (h *Handler) ApplyConfig(newCfg *config.Config) {
	if newCfg.Workers != h.cfg.Workers {
		h.workerPool.Resize(newCfg.Workers)
	}

	if newCfg.HideProcessingTmp != h.cfg.HideProcessingTmp {
		h.browser.SetHideProcessingTmp(newCfg.HideProcessingTmp)
	}

	if newCfg.MediaPath != "" && newCfg.MediaPath != h.cfg.MediaPath {
		h.browser.SetMediaRoot(newCfg.MediaPath)
	}

	h.cfg.MediaPath = newCfg.MediaPath
	h.cfg.TempPath = newCfg.TempPath
	h.cfg.OriginalHandling = newCfg.OriginalHandling
	h.cfg.SubtitleHandling = newCfg.SubtitleHandling
	h.cfg.Workers = newCfg.Workers
	h.cfg.FFmpegPath = newCfg.FFmpegPath
	h.cfg.FFprobePath = newCfg.FFprobePath
	h.cfg.PushoverUserKey = newCfg.PushoverUserKey
	h.cfg.PushoverAppToken = newCfg.PushoverAppToken
	h.cfg.NtfyServer = newCfg.NtfyServer
	h.cfg.NtfyTopic = newCfg.NtfyTopic
	h.cfg.NtfyToken = newCfg.NtfyToken
	h.cfg.NotifyOnComplete = newCfg.NotifyOnComplete
	h.cfg.HideProcessingTmp = newCfg.HideProcessingTmp
	h.cfg.AllowSoftwareFallback = newCfg.AllowSoftwareFallback
	h.cfg.Layout = newCfg.Layout
	h.cfg.Features = newCfg.Features

	h.pushover.UserKey = newCfg.PushoverUserKey
	h.pushover.AppToken = newCfg.PushoverAppToken
	h.ntfy.ServerURL = newCfg.NtfyServer
	h.ntfy.Topic = newCfg.NtfyTopic
	h.ntfy.Token = newCfg.NtfyToken
}

// RetryJob handles POST /api/jobs/:id/retry
func (h *Handler) RetryJob(w http.ResponseWriter, r *http.Request) {
	id := r.PathValue("id")
	if id == "" {
		writeError(w, http.StatusBadRequest, "job ID required")
		return
	}

	job := h.queue.Get(id)
	if job == nil {
		writeError(w, http.StatusNotFound, "job not found")
		return
	}

	if job.Status != jobs.StatusFailed {
		writeError(w, http.StatusBadRequest, "can only retry failed jobs")
		return
	}

	// Re-probe the file and create a new job
	ctx, cancel := context.WithTimeout(r.Context(), 30*time.Second)
	defer cancel()

	probe, err := h.browser.ProbeFile(ctx, job.InputPath)
	if err != nil {
		writeError(w, http.StatusBadRequest, fmt.Sprintf("failed to probe file: %v", err))
		return
	}

	// Add new job with same preset
	newJob, err := h.queue.Add(job.InputPath, job.PresetID, probe)
	if err != nil {
		writeError(w, http.StatusInternalServerError, fmt.Sprintf("failed to create job: %v", err))
		return
	}

	// Remove the failed job
	if _, err := h.queue.Remove(id); err != nil {
		log.Printf("Failed to remove job %s after retry: %v", id, err)
	}

	writeJSON(w, http.StatusOK, newJob)
}

// ForceRetryJob handles POST /api/jobs/:id/force
// This resets a skipped or no_gain job to pending with ForceTranscode enabled,
// bypassing skip checks and size comparison.
func (h *Handler) ForceRetryJob(w http.ResponseWriter, r *http.Request) {
	id := r.PathValue("id")
	if id == "" {
		writeError(w, http.StatusBadRequest, "job ID required")
		return
	}

	job := h.queue.Get(id)
	if job == nil {
		writeError(w, http.StatusNotFound, "job not found")
		return
	}

	if job.Status != jobs.StatusSkipped && job.Status != jobs.StatusNoGain {
		writeError(w, http.StatusBadRequest, "can only force retry skipped or no_gain jobs")
		return
	}

	if err := h.queue.ForceRetryJob(id); err != nil {
		writeError(w, http.StatusInternalServerError, fmt.Sprintf("failed to force retry: %v", err))
		return
	}

	// Get updated job
	updatedJob := h.queue.Get(id)
	writeJSON(w, http.StatusOK, updatedJob)
}

// RetryWithPresetRequest is the request body for RetryWithPreset
type RetryWithPresetRequest struct {
	PresetID string `json:"preset_id"`
}

// RetryWithPreset handles POST /api/jobs/:id/retry-preset
// This creates a new job with a different preset for skipped or no_gain jobs.
func (h *Handler) RetryWithPreset(w http.ResponseWriter, r *http.Request) {
	id := r.PathValue("id")
	if id == "" {
		writeError(w, http.StatusBadRequest, "job ID required")
		return
	}

	var req RetryWithPresetRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		writeError(w, http.StatusBadRequest, "invalid request body")
		return
	}

	if req.PresetID == "" {
		writeError(w, http.StatusBadRequest, "preset_id required")
		return
	}

	// Validate preset exists
	preset := ffmpeg.GetPreset(req.PresetID)
	if preset == nil {
		writeError(w, http.StatusBadRequest, fmt.Sprintf("unknown preset: %s", req.PresetID))
		return
	}

	job := h.queue.Get(id)
	if job == nil {
		writeError(w, http.StatusNotFound, "job not found")
		return
	}

	if job.Status != jobs.StatusSkipped && job.Status != jobs.StatusNoGain {
		writeError(w, http.StatusBadRequest, "can only retry skipped or no_gain jobs with a different preset")
		return
	}

	// Re-probe the file
	ctx, cancel := context.WithTimeout(r.Context(), 30*time.Second)
	defer cancel()

	probe, err := h.browser.ProbeFile(ctx, job.InputPath)
	if err != nil {
		writeError(w, http.StatusBadRequest, fmt.Sprintf("failed to probe file: %v", err))
		return
	}

	// Add new job with new preset
	newJob, err := h.queue.Add(job.InputPath, req.PresetID, probe)
	if err != nil {
		writeError(w, http.StatusInternalServerError, fmt.Sprintf("failed to create job: %v", err))
		return
	}

	// Remove the old job
	if _, err := h.queue.Remove(id); err != nil {
		log.Printf("Failed to remove job %s after retry with preset: %v", id, err)
	}

	writeJSON(w, http.StatusOK, newJob)
}
